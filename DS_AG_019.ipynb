{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40fbc5c4",
   "metadata": {},
   "source": [
    "# Question 1 : What is Deep Learning? Briefly describe how it evolved and how it differs from traditional machine learning.\n",
    "\n",
    "### Answer  \n",
    "## 1. What is Deep Learning?\n",
    "\n",
    "**Deep Learning** is a subfield of **Machine Learning** that uses **artificial neural networks with multiple hidden layers** (deep neural networks) to automatically learn complex patterns and representations from large volumes of data.\n",
    "\n",
    "Unlike traditional machine learning, deep learning models perform **automatic feature extraction**, reducing the need for manual feature engineering. Deep learning is widely used in areas such as image recognition, speech processing, natural language processing, and autonomous systems.\n",
    "\n",
    "## 2. Evolution of Deep Learning\n",
    "\n",
    "The development of deep learning occurred gradually over several decades:\n",
    "\n",
    "- ### Early Neural Networks (1950s–1980s)\n",
    "    - Introduction of the **Perceptron** by Frank Rosenblatt.\n",
    "    - Limited to single-layer models.\n",
    "    - Failed to solve non-linearly separable problems.\n",
    "    - Research slowed due to computational limitations.\n",
    "\n",
    "- ### Revival with Multi-Layer Networks (1990s)\n",
    "    - Introduction of **Multi-Layer Perceptrons (MLPs)**.\n",
    "    - Use of **backpropagation algorithm** for training.\n",
    "    - Still limited by slow computation and small datasets.\n",
    "\n",
    "- ### Breakthrough Era (2006–2012)\n",
    "    - Development of better activation functions (ReLU).\n",
    "    - Availability of **large datasets** and **GPUs**.\n",
    "    - Improved optimization techniques (Adam, RMSprop).\n",
    "    - Success in image and speech recognition tasks.\n",
    "\n",
    "- ### Modern Deep Learning (2012–Present)\n",
    "    - Breakthrough of deep networks in competitions like ImageNet.\n",
    "    - Emergence of **CNNs**, **RNNs**, **LSTMs**, and **Transformers**.\n",
    "    - Widespread adoption in industry and research.\n",
    "\n",
    "## 3. Difference Between Deep Learning and Traditional Machine Learning\n",
    "\n",
    "| Aspect | Traditional Machine Learning | Deep Learning |\n",
    "|------|-----------------------------|---------------|\n",
    "| Feature Engineering | Manual | Automatic |\n",
    "| Model Depth | Shallow models | Deep neural networks |\n",
    "| Data Requirement | Works with small datasets | Requires large datasets |\n",
    "| Computational Power | Low to moderate | High (GPUs/TPUs) |\n",
    "| Performance on Complex Data | Limited | Very high |\n",
    "| Interpretability | Easier to interpret | Often a black box |\n",
    "| Examples | Linear Regression, SVM | CNN, RNN, Transformers |\n",
    "\n",
    "## 4. Key Differences:\n",
    "\n",
    "- ### Feature Extraction\n",
    "    - Traditional ML relies on **hand-crafted features**.\n",
    "    - Deep learning learns hierarchical features directly from raw data.\n",
    "\n",
    "- ### Scalability\n",
    "    - Traditional ML struggles with very large and unstructured data.\n",
    "    - Deep learning scales well with big data and complex inputs.\n",
    "\n",
    "- ### Accuracy\n",
    "    - Deep learning generally achieves higher accuracy for tasks like vision and language.\n",
    "    - Traditional ML performs well on structured data with limited complexity.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8477b547",
   "metadata": {},
   "source": [
    "# Question 2 : Explain the basic architecture and functioning of a Perceptron. What are its limitations?\n",
    "\n",
    "### Answer  \n",
    "A **Perceptron** is the simplest model of an artificial neural network and forms the foundation of modern neural network architectures. It was proposed by *Frank Rosenblatt* and is mainly used for **binary classification problems**. The perceptron is inspired by the biological neuron and performs a linear classification task.\n",
    "\n",
    "## 2. Basic Architecture of a Perceptron\n",
    "\n",
    "A perceptron consists of the following components:\n",
    "\n",
    "- ### Input Layer\n",
    "    - Inputs are feature values represented as:\n",
    "    \\[\n",
    "    x = (x_1, x_2, x_3, \\dots, x_n)\n",
    "    \\]\n",
    "\n",
    "- ### Weights\n",
    "    - Each input is associated with a weight:\n",
    "    \\[\n",
    "    w = (w_1, w_2, w_3, \\dots, w_n)\n",
    "    \\]\n",
    "    - Weights determine the importance of each input.\n",
    "\n",
    "- ### Bias\n",
    "    - A bias term \\( b \\) is added to the weighted sum.\n",
    "    - It helps shift the decision boundary.\n",
    "\n",
    "- ### Summation Unit\n",
    "    - Computes the net input:\n",
    "    \\[\n",
    "    z = \\sum_{i=1}^{n} w_i x_i + b\n",
    "    \\]\n",
    "\n",
    "- ### Activation Function\n",
    "    - The perceptron uses a **step (threshold) function**:\n",
    "    \\[\n",
    "    f(z) =\n",
    "    \\begin{cases}\n",
    "    1, & \\text{if } z \\ge 0 \\\\\n",
    "    0, & \\text{if } z < 0\n",
    "    \\end{cases}\n",
    "    \\]\n",
    "    - Produces a binary output.\n",
    "\n",
    "\n",
    "## 3. Functioning of a Perceptron\n",
    "\n",
    "The working of a perceptron can be explained in the following steps:\n",
    "\n",
    "1. **Input Feeding**  \n",
    "   Feature values are provided as input to the perceptron.\n",
    "\n",
    "2. **Weighted Sum Calculation**  \n",
    "   Each input is multiplied by its corresponding weight and summed with the bias.\n",
    "\n",
    "3. **Activation**  \n",
    "   The weighted sum is passed through the step activation function.\n",
    "\n",
    "4. **Output Generation**  \n",
    "   - Output = 1 → Input belongs to the positive class  \n",
    "   - Output = 0 → Input belongs to the negative class\n",
    "\n",
    "5. **Learning (Weight Update Rule)**  \n",
    "   If the predicted output is incorrect, the weights and bias are updated using:\n",
    "\\[\n",
    "w_i = w_i + \\eta (y - \\hat{y}) x_i\n",
    "\\]\n",
    "\\[\n",
    "b = b + \\eta (y - \\hat{y})\n",
    "\\]\n",
    "where:\n",
    "- \\( \\eta \\) = learning rate  \n",
    "- \\( y \\) = actual output  \n",
    "- \\( \\hat{y} \\) = predicted output  \n",
    "\n",
    "\n",
    "## 4. Decision Boundary\n",
    "\n",
    "- The perceptron creates a **linear decision boundary** (a straight line in 2D or a hyperplane in higher dimensions).\n",
    "- It can correctly classify data only if it is **linearly separable**.\n",
    "\n",
    "\n",
    "## 5. Limitations of a Perceptron\n",
    "\n",
    "- ### Inability to Solve Non-Linear Problems\n",
    "    - Cannot solve problems like **XOR**, which are not linearly separable.\n",
    "\n",
    "- ### Single-Layer Structure\n",
    "    - Contains only one layer of trainable weights.\n",
    "    - Cannot learn complex patterns or hierarchical representations.\n",
    "\n",
    "- ### Binary Output Only\n",
    "    - Produces only binary outputs (0 or 1).\n",
    "    - Not suitable for multi-class classification without extensions.\n",
    "\n",
    "- ### Non-Differentiable Activation Function\n",
    "    - The step function is not differentiable.\n",
    "    - Gradient-based optimization methods cannot be applied.\n",
    "\n",
    "- ### Limited Practical Usage\n",
    "    - Rarely used in real-world applications.\n",
    "    - Mainly important for theoretical understanding.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69749ca5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Question 3 : Describe the purpose of activation functions in neural networks. Compare Sigmoid, ReLU, and Tanh.\n",
    "\n",
    "### Answer  \n",
    "## 1. Purpose of Activation Functions\n",
    "\n",
    "Activation functions are mathematical functions applied to the output of a neuron to decide whether the neuron should be activated or not. They introduce **non-linearity** into the neural network, enabling it to learn complex patterns and relationships in data.\n",
    "\n",
    "### Key Purposes:\n",
    "- **Introduce non-linearity** so the network can model complex functions.\n",
    "- **Control the output range** of neurons.\n",
    "- **Enable deep networks** to learn hierarchical representations.\n",
    "- **Determine neuron activation**, influencing information flow.\n",
    "\n",
    "Without activation functions, a neural network would behave like a linear model regardless of its depth.\n",
    "\n",
    "## 2. Sigmoid Activation Function\n",
    "\n",
    "The Sigmoid function maps input values into the range \\( (0, 1) \\).\n",
    "\n",
    "\\[\n",
    "\\sigma(x) = \\frac{1}{1 + e^{-x}}\n",
    "\\]\n",
    "\n",
    "### Characteristics\n",
    "- Smooth and differentiable.\n",
    "- Outputs can be interpreted as probabilities.\n",
    "\n",
    "### Advantages\n",
    "- Useful for **binary classification output layers**.\n",
    "- Historically important.\n",
    "\n",
    "### Disadvantages\n",
    "- Suffers from the **vanishing gradient problem**.\n",
    "- Outputs are not zero-centered.\n",
    "- Slow convergence in deep networks.\n",
    "\n",
    "## 3. Tanh (Hyperbolic Tangent) Activation Function\n",
    "\n",
    "The Tanh function maps input values into the range \\( (-1, 1) \\).\n",
    "\n",
    "\\[\n",
    "\\tanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}\n",
    "\\]\n",
    "\n",
    "### Characteristics\n",
    "- Zero-centered output.\n",
    "- Stronger gradients than sigmoid.\n",
    "\n",
    "### Advantages\n",
    "- Faster convergence than sigmoid.\n",
    "- Better for hidden layers in shallow networks.\n",
    "\n",
    "### Disadvantages\n",
    "- Still suffers from vanishing gradients.\n",
    "- Computationally expensive.\n",
    "\n",
    "## 4. ReLU (Rectified Linear Unit) Activation Function\n",
    "\n",
    "ReLU outputs the input directly if positive; otherwise, it outputs zero.\n",
    "\n",
    "\\[\n",
    "\\text{ReLU}(x) = \\max(0, x)\n",
    "\\]\n",
    "\n",
    "### Characteristics\n",
    "- Simple and computationally efficient.\n",
    "- Produces sparse activations.\n",
    "\n",
    "### Advantages\n",
    "- Avoids vanishing gradient problem (for positive inputs).\n",
    "- Faster training and convergence.\n",
    "- Widely used in deep networks.\n",
    "\n",
    "### Disadvantages\n",
    "- **Dying ReLU problem** (neurons may stop activating).\n",
    "- Not zero-centered for positive values.\n",
    "\n",
    "## 5. Comparison Table\n",
    "\n",
    "| Feature | Sigmoid | Tanh | ReLU |\n",
    "|------|--------|------|------|\n",
    "| Output Range | (0, 1) | (-1, 1) | [0, ∞) |\n",
    "| Zero-Centered | No | Yes | No |\n",
    "| Vanishing Gradient | Yes | Yes | No (partially) |\n",
    "| Computational Cost | High | High | Low |\n",
    "| Common Usage | Output layer | Hidden layers | Hidden layers |\n",
    "| Sparsity | No | No | Yes |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d02917",
   "metadata": {},
   "source": [
    "# Question 4  \n",
    "## What is the difference between Loss function and Cost function in neural networks? Provide examples.\n",
    "\n",
    "### Answer  \n",
    "In neural networks, **Loss functions** and **Cost functions** are used to measure how well a model is performing. Although these terms are often used interchangeably, they have **distinct meanings** in theory and academic contexts.\n",
    "\n",
    "## 2. Loss Function\n",
    "\n",
    "A **Loss Function** measures the error for **a single training example** by comparing the predicted output with the actual (true) output.\n",
    "\n",
    "It answers the question:  \n",
    "> *How wrong is the model for this one data point?*\n",
    "\n",
    "### Mathematical Representation\n",
    "For a single data point \\( (x, y) \\):\n",
    "\n",
    "\\[\n",
    "L(y, \\hat{y})\n",
    "\\]\n",
    "\n",
    "where:\n",
    "- \\( y \\) = actual output  \n",
    "- \\( \\hat{y} \\) = predicted output  \n",
    "\n",
    "### Examples of Loss Functions\n",
    "\n",
    "1. **Mean Squared Error (MSE) – per sample**\n",
    "\\[\n",
    "L = (y - \\hat{y})^2\n",
    "\\]\n",
    "\n",
    "2. **Binary Cross-Entropy Loss**\n",
    "\\[\n",
    "L = - \\left[ y \\log(\\hat{y}) + (1 - y)\\log(1 - \\hat{y}) \\right]\n",
    "\\]\n",
    "\n",
    "3. **Hinge Loss (used in SVMs)**\n",
    "\\[\n",
    "L = \\max(0, 1 - y\\hat{y})\n",
    "\\]\n",
    "\n",
    "### Key Points\n",
    "- Calculated **per data sample**\n",
    "- Used directly during **backpropagation**\n",
    "- Represents **individual prediction error**\n",
    "\n",
    "## 3. Cost Function\n",
    "\n",
    "A **Cost Function** measures the **average (or total) loss over the entire dataset** or a batch of data.\n",
    "\n",
    "It answers the question:  \n",
    "> *How well is the model performing overall?*\n",
    "\n",
    "### Mathematical Representation\n",
    "For a dataset with \\( N \\) samples:\n",
    "\n",
    "\\[\n",
    "J = \\frac{1}{N} \\sum_{i=1}^{N} L(y_i, \\hat{y}_i)\n",
    "\\]\n",
    "\n",
    "### Examples of Cost Functions\n",
    "\n",
    "1. **Mean Squared Error (Cost)**\n",
    "\\[\n",
    "J = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2\n",
    "\\]\n",
    "\n",
    "2. **Cross-Entropy Cost Function**\n",
    "\\[\n",
    "J = -\\frac{1}{N} \\sum_{i=1}^{N} \\left[ y_i \\log(\\hat{y}_i) + (1 - y_i)\\log(1 - \\hat{y}_i) \\right]\n",
    "\\]\n",
    "\n",
    "3. **Log Loss (Classification)**\n",
    "- Average of individual log losses over all samples.\n",
    "\n",
    "### Key Points\n",
    "- Computed over **entire dataset or mini-batch**\n",
    "- Used by **optimizers** to update model parameters\n",
    "- Represents **overall model performance**\n",
    "\n",
    "## 4. Key Differences Between Loss and Cost Functions\n",
    "\n",
    "| Aspect | Loss Function | Cost Function |\n",
    "|------|--------------|---------------|\n",
    "| Scope | Single data point | Entire dataset / batch |\n",
    "| Purpose | Measures individual error | Measures overall error |\n",
    "| Usage | Used internally per sample | Used for optimization |\n",
    "| Notation | \\( L(y, \\hat{y}) \\) | \\( J(\\theta) \\) |\n",
    "| Dependency | One prediction | All predictions |\n",
    "\n",
    "## 5. Relationship Between Loss and Cost Function\n",
    "\n",
    "- The **cost function is derived from the loss function**.\n",
    "- Cost function is simply the **average or sum of losses**.\n",
    "- Optimizers aim to **minimize the cost function**, not individual losses.\n",
    "\n",
    "\n",
    "Understanding this distinction is important for theoretical clarity, even though many practical implementations use the terms interchangeably.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511f00cf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Question 5  \n",
    "## What is the role of optimizers in neural networks? Compare Gradient Descent, Adam, and RMSprop.\n",
    "\n",
    "### Answer  \n",
    "In neural networks, **optimizers** are algorithms used to update the model’s parameters (weights and biases) during training so as to **minimize the loss function**. They play a crucial role in determining how fast a model converges, how stable the training process is, and whether the model reaches a good (or optimal) solution.\n",
    "\n",
    "\n",
    "## 2. Role of Optimizers\n",
    "\n",
    "Optimizers perform the following key functions:\n",
    "\n",
    "1. **Parameter Update**  \n",
    "   They adjust weights and biases based on gradients computed using backpropagation.\n",
    "\n",
    "2. **Loss Minimization**  \n",
    "   By iteratively updating parameters, optimizers aim to reduce training loss and improve model accuracy.\n",
    "\n",
    "3. **Control of Learning Speed**  \n",
    "   Optimizers determine how large or small each update step should be through learning rates and adaptive mechanisms.\n",
    "\n",
    "4. **Handling Complex Loss Surfaces**  \n",
    "   Neural network loss functions are often non-convex with local minima, saddle points, and plateaus. Optimizers help navigate these efficiently.\n",
    "\n",
    "5. **Stability and Convergence**  \n",
    "   A good optimizer prevents oscillations, divergence, or extremely slow learning.\n",
    "\n",
    "\n",
    "### 3. Gradient Descent (GD)\n",
    "\n",
    "Gradient Descent is the most basic optimization algorithm. It updates parameters in the **opposite direction of the gradient** of the loss function.\n",
    "\n",
    "### Update Rule\n",
    "\\[\n",
    "\\theta = \\theta - \\eta \\cdot \\nabla J(\\theta)\n",
    "\\]\n",
    "where:\n",
    "- \\(\\theta\\) = parameters  \n",
    "- \\(\\eta\\) = learning rate  \n",
    "- \\(\\nabla J(\\theta)\\) = gradient of loss  \n",
    "\n",
    "### Characteristics\n",
    "- Uses a **fixed learning rate**\n",
    "- Computes gradients over the entire dataset (Batch Gradient Descent)\n",
    "\n",
    "### Advantages\n",
    "- Simple and easy to understand  \n",
    "- Stable convergence for small datasets  \n",
    "\n",
    "### Disadvantages\n",
    "- Slow for large datasets  \n",
    "- Sensitive to learning rate choice  \n",
    "- Can get stuck in local minima or saddle points  \n",
    "\n",
    "\n",
    "### 4. RMSprop (Root Mean Square Propagation)\n",
    "\n",
    "RMSprop is an **adaptive learning rate optimizer** that adjusts the learning rate for each parameter individually using a moving average of squared gradients.\n",
    "\n",
    "### Update Rule\n",
    "\\[\n",
    "v_t = \\beta v_{t-1} + (1 - \\beta)(\\nabla J(\\theta))^2\n",
    "\\]\n",
    "\\[\n",
    "\\theta = \\theta - \\frac{\\eta}{\\sqrt{v_t + \\epsilon}} \\cdot \\nabla J(\\theta)\n",
    "\\]\n",
    "\n",
    "### Characteristics\n",
    "- Learning rate decreases for parameters with large gradients  \n",
    "- Well-suited for **non-stationary** objectives  \n",
    "\n",
    "### Advantages\n",
    "- Faster convergence than standard Gradient Descent  \n",
    "- Reduces oscillations in steep directions  \n",
    "- Works well for recurrent and deep networks  \n",
    "\n",
    "### Disadvantages\n",
    "- Requires tuning of hyperparameters  \n",
    "- Does not include bias correction  \n",
    "\n",
    "\n",
    "### 5. Adam (Adaptive Moment Estimation)\n",
    "\n",
    "Adam combines the ideas of **Momentum** and **RMSprop** by maintaining both:\n",
    "- First moment (mean of gradients)\n",
    "- Second moment (mean of squared gradients)\n",
    "\n",
    "### Update Rule\n",
    "\\[\n",
    "m_t = \\beta_1 m_{t-1} + (1 - \\beta_1)\\nabla J(\\theta)\n",
    "\\]\n",
    "\\[\n",
    "v_t = \\beta_2 v_{t-1} + (1 - \\beta_2)(\\nabla J(\\theta))^2\n",
    "\\]\n",
    "\n",
    "Bias-corrected estimates:\n",
    "\\[\n",
    "\\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t}, \\quad\n",
    "\\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t}\n",
    "\\]\n",
    "\n",
    "Final update:\n",
    "\\[\n",
    "\\theta = \\theta - \\frac{\\eta}{\\sqrt{\\hat{v}_t} + \\epsilon} \\cdot \\hat{m}_t\n",
    "\\]\n",
    "\n",
    "### Characteristics\n",
    "- Adaptive learning rates  \n",
    "- Includes momentum and bias correction  \n",
    "\n",
    "### Advantages\n",
    "- Very fast convergence  \n",
    "- Works well with sparse gradients  \n",
    "- Minimal tuning required  \n",
    "- Most widely used optimizer in practice  \n",
    "\n",
    "### Disadvantages\n",
    "- Can sometimes converge to suboptimal solutions  \n",
    "- Slightly higher computational cost  \n",
    "\n",
    "\n",
    "### 6. Comparison Table\n",
    "\n",
    "| Feature | Gradient Descent | RMSprop | Adam |\n",
    "|------|----------------|---------|------|\n",
    "| Learning Rate | Fixed | Adaptive | Adaptive |\n",
    "| Momentum | No | No | Yes |\n",
    "| Squared Gradients | No | Yes | Yes |\n",
    "| Bias Correction | No | No | Yes |\n",
    "| Convergence Speed | Slow | Faster | Fastest |\n",
    "| Stability | Moderate | High | Very High |\n",
    "| Common Use | Small datasets | RNNs, deep nets | Most DL tasks |\n",
    "\n",
    "In practice, **Adam is generally preferred**, while Gradient Descent is mainly used for conceptual understanding and small-scale problems.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ca4619",
   "metadata": {},
   "source": [
    "# Question 6 : Write a Python program to implement a single-layer perceptron from scratch using NumPy to solve the logical AND gate\n",
    "\n",
    "### Explanation  \n",
    "The AND gate is linearly separable and can be solved using a perceptron. The model learns weights that activate only when both inputs are 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6153ece4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [0.2 0.1]\n",
      "Bias: -0.20000000000000004\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = np.array([0,0,0,1])\n",
    "\n",
    "w = np.zeros(2)\n",
    "b = 0\n",
    "lr = 0.1\n",
    "\n",
    "for _ in range(10):\n",
    "    for i in range(len(X)):\n",
    "        y_pred = 1 if np.dot(X[i], w) + b >= 0 else 0\n",
    "        w += lr * (y[i] - y_pred) * X[i]\n",
    "        b += lr * (y[i] - y_pred)\n",
    "\n",
    "print(\"Weights:\", w)\n",
    "print(\"Bias:\", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c0f1f8-c145-4b38-aa84-11078a16a555",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7edf64",
   "metadata": {},
   "source": [
    "# Question 7: Implement and visualize Sigmoid, ReLU, and Tanh activation functions using Matplotlib.\n",
    "\n",
    "### Explanation  \n",
    "Visualization helps understand the response of activation functions to varying input values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ac23754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(-10, 10, 200)\n",
    "sigmoid = 1 / (1 + np.exp(-x))\n",
    "relu = np.maximum(0, x)\n",
    "tanh = np.tanh(x)\n",
    "\n",
    "plt.plot(x, sigmoid, label='Sigmoid')\n",
    "plt.plot(x, relu, label='ReLU')\n",
    "plt.plot(x, tanh, label='Tanh')\n",
    "plt.legend()\n",
    "plt.title(\"Activation Functions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a250eb1a-d5b7-4201-9430-801dcb346adc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2521523b",
   "metadata": {},
   "source": [
    "# Question 8: Use Keras to build and train a simple multilayer neural network on the MNIST digits dataset. Print the training accuracy.\n",
    "\n",
    "### Explanation  \n",
    "A simple dense neural network is trained to classify handwritten digits. Accuracy reflects learning performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd84c19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
      "Epoch 1/3\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9266 - loss: 0.2557\n",
      "Epoch 2/3\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.9659 - loss: 0.1142\n",
      "Epoch 3/3\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9757 - loss: 0.0789\n",
      "Training Accuracy: 0.9757000207901001\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "(X_train, y_train), _ = mnist.load_data()\n",
    "X_train = X_train / 255.0\n",
    "y_train = to_categorical(y_train)\n",
    "model = Sequential([\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=3, verbose=1)\n",
    "\n",
    "print(\"Training Accuracy:\", history.history['accuracy'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84b3d5a-c9c1-4711-b3e4-f4dea7cad568",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42a86bb",
   "metadata": {},
   "source": [
    "# Question 9: Visualize the loss and accuracy curves for a neural network model trained on the Fashion MNIST dataset. Interpret the training behavior.\n",
    "\n",
    "### Explanation  \n",
    "Training curves indicate convergence behavior and potential overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2c6e915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
      "Epoch 1/3\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8276 - loss: 0.5083\n",
      "Epoch 2/3\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8665 - loss: 0.3696\n",
      "Epoch 3/3\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8779 - loss: 0.3375\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(X_train, y_train), _ = fashion_mnist.load_data()\n",
    "X_train = X_train / 255.0\n",
    "y_train = to_categorical(y_train)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=3, verbose=1)\n",
    "plt.plot(model.history.history['accuracy'], label='Accuracy')\n",
    "plt.plot(model.history.history['loss'], label='Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de153e21-c715-450b-bb02-9a910436fd2a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d60b1f6",
   "metadata": {},
   "source": [
    "# Question 10 :  You are working on a project for a bank that wants to automatically detect fraudulent transactions. The dataset is large, imbalanced, and contains structured features like transaction amount, merchant ID, and customer location. The goal is to classify each transaction as fraudulent or legitimate.\n",
    "\n",
    "# Explain your real-time data science workflow:\n",
    "    ● How would you design a deep learning model (perceptron or multilayer NN)?\n",
    "    ● Which activation function and loss function would you use, and why?\n",
    "    ● How would you train and evaluate the model, considering class imbalance?\n",
    "    ● Which optimizer would be suitable, and how would you prevent overfitting?\n",
    "\n",
    "### Answer  \n",
    "# Project: Real-Time Credit Card Fraud Detection System\n",
    "\n",
    "## 1. Real-Time Data Science Workflow\n",
    "\n",
    "To handle high-throughput banking transactions, I would design a **low-latency, scalable pipeline** with the following components:\n",
    "\n",
    "**Data Ingestion**  \n",
    "Transactions are streamed in real time using distributed messaging systems such as **Apache Kafka**, which ensures fault tolerance and high throughput.\n",
    "\n",
    "**Preprocessing Pipeline**  \n",
    "Incoming transactions must undergo the **exact same preprocessing steps** used during model training:\n",
    "- Feature scaling using `StandardScaler`\n",
    "- Encoding of categorical variables  \n",
    "This guarantees data consistency and prevents training–inference mismatch.\n",
    "\n",
    "**Inference Engine**  \n",
    "A pre-trained Deep Learning model processes each transaction and outputs a **fraud probability score between 0 and 1**.\n",
    "\n",
    "**Decision Logic**\n",
    "- **Score < 0.90** → Automatically approve the transaction  \n",
    "- **Score ≥ 0.90** → Flag for immediate manual review or automatically block  \n",
    "\n",
    "The threshold is chosen to prioritize fraud capture while controlling false positives.\n",
    "\n",
    "**Feedback Loop**  \n",
    "Once transactions are verified as **fraudulent or legitimate**, the confirmed labels are stored in a database. These labels are periodically used to **retrain and update the model**, allowing it to adapt to new fraud patterns.\n",
    "\n",
    "## 2. Deep Learning Model Design\n",
    "\n",
    "**Model Choice: Multilayer Perceptron (MLP)**\n",
    "\n",
    "**Why not a Simple Perceptron?**  \n",
    "A single perceptron is a **linear classifier**. Credit card fraud patterns are highly **non-linear**, involving complex interactions between variables such as transaction amount, time, location, and user behavior. A simple perceptron cannot capture these relationships.\n",
    "\n",
    "**Architecture**\n",
    "- **Input Layer:** One neuron per feature (e.g., 30 features)\n",
    "- **Hidden Layers:**  \n",
    "  - Dense layer with 32 neurons  \n",
    "  - Dense layer with 16 neurons  \n",
    "  These layers learn hierarchical and non-linear feature interactions.\n",
    "- **Output Layer:**  \n",
    "  - 1 neuron for binary classification (fraud vs legitimate)\n",
    "\n",
    "## 3. Activation & Loss Functions\n",
    "\n",
    "**Hidden Layer Activation: ReLU (Rectified Linear Unit)**  \n",
    "- Computationally efficient  \n",
    "- Mitigates the *vanishing gradient* problem  \n",
    "- Enables faster and more stable learning in deep networks\n",
    "\n",
    "**Output Layer Activation: Sigmoid**  \n",
    "- Compresses output into the range **[0, 1]**  \n",
    "- Interpretable as the **probability of fraud**\n",
    "\n",
    "**Loss Function: Binary Cross-Entropy (Log Loss)**  \n",
    "- Standard loss function for binary classification  \n",
    "- Strongly penalizes confident but incorrect predictions  \n",
    "- Particularly important in high-risk domains like fraud detection\n",
    "\n",
    "## 4. Handling Class Imbalance (Training & Evaluation)\n",
    "\n",
    "**The Challenge**  \n",
    "Fraud cases are extremely rare (often **<1%**). A naive model could achieve very high accuracy by predicting every transaction as legitimate, which is unacceptable.\n",
    "\n",
    "**Training Strategy: Class Weights**  \n",
    "- Assign a **higher weight to the fraud class (Class 1)** during training  \n",
    "- This makes missing a fraud case significantly more costly than misclassifying a legitimate transaction  \n",
    "- Forces the model to focus on minority-class detection\n",
    "\n",
    "**Evaluation Metrics (Accuracy is Ignored)**\n",
    "- **Recall (Sensitivity):** Most critical metric; measures how many fraud cases are caught  \n",
    "- **Precision:** Controls false positives and unnecessary transaction blocks  \n",
    "- **F1-Score:** Balances precision and recall  \n",
    "- **AUC-ROC:** Measures class separability across all thresholds\n",
    "\n",
    "## 5. Optimizer & Preventing Overfitting\n",
    "\n",
    "**Optimizer: Adam**  \n",
    "- Uses adaptive learning rates for each parameter  \n",
    "- Combines the advantages of momentum and RMSProp  \n",
    "- Converges faster and more reliably than standard SGD on complex datasets\n",
    "\n",
    "**Overfitting Prevention Techniques**\n",
    "\n",
    "**Dropout (0.5)**  \n",
    "- Randomly disables 50% of neurons during training  \n",
    "- Forces the network to learn robust, generalized feature representations  \n",
    "- Reduces dependency on specific neurons\n",
    "\n",
    "**Early Stopping**  \n",
    "- Monitors validation loss during training  \n",
    "- Automatically stops training when performance stops improving  \n",
    "- Ensures the final model represents the **best generalization**, not an overfitted one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57f89c21-ab47-4af2-af2e-93a8ac0fd4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data...\n",
      "Data generated. Shape: (50000, 31)\n",
      "Fraud cases: 757\n",
      "Preprocessing data...\n",
      "Weight for Legit (0): 0.51\n",
      "Weight for Fraud (1): 33.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rk\\tf_env\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n",
      "Epoch 1/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - auc: 0.5150 - loss: 0.8141 - precision: 0.0191 - recall: 0.3180 - val_auc: 0.6305 - val_loss: 0.7875 - val_precision: 0.0151 - val_recall: 0.7736\n",
      "Epoch 2/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc: 0.5834 - loss: 0.7004 - precision: 0.0183 - recall: 0.5620 - val_auc: 0.6961 - val_loss: 0.8097 - val_precision: 0.0156 - val_recall: 0.8585\n",
      "Epoch 3/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc: 0.6347 - loss: 0.6729 - precision: 0.0214 - recall: 0.6360 - val_auc: 0.7373 - val_loss: 0.7763 - val_precision: 0.0174 - val_recall: 0.8491\n",
      "Epoch 4/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc: 0.6710 - loss: 0.6511 - precision: 0.0236 - recall: 0.6520 - val_auc: 0.7565 - val_loss: 0.7593 - val_precision: 0.0188 - val_recall: 0.8208\n",
      "Epoch 5/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc: 0.6912 - loss: 0.6380 - precision: 0.0271 - recall: 0.6460 - val_auc: 0.7610 - val_loss: 0.7363 - val_precision: 0.0214 - val_recall: 0.8113\n",
      "Epoch 6/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - auc: 0.7186 - loss: 0.6161 - precision: 0.0299 - recall: 0.6700 - val_auc: 0.7635 - val_loss: 0.6882 - val_precision: 0.0248 - val_recall: 0.7642\n",
      "Epoch 7/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc: 0.7310 - loss: 0.6059 - precision: 0.0337 - recall: 0.6280 - val_auc: 0.7718 - val_loss: 0.7051 - val_precision: 0.0244 - val_recall: 0.7642\n",
      "Epoch 8/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc: 0.7449 - loss: 0.5989 - precision: 0.0348 - recall: 0.6760 - val_auc: 0.7786 - val_loss: 0.6331 - val_precision: 0.0311 - val_recall: 0.7358\n",
      "Epoch 9/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc: 0.7583 - loss: 0.5824 - precision: 0.0387 - recall: 0.6560 - val_auc: 0.7868 - val_loss: 0.6465 - val_precision: 0.0294 - val_recall: 0.7170\n",
      "Epoch 10/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - auc: 0.7606 - loss: 0.5787 - precision: 0.0378 - recall: 0.6660 - val_auc: 0.7956 - val_loss: 0.6038 - val_precision: 0.0345 - val_recall: 0.7075\n",
      "Epoch 11/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - auc: 0.7679 - loss: 0.5690 - precision: 0.0423 - recall: 0.6380 - val_auc: 0.8005 - val_loss: 0.5942 - val_precision: 0.0355 - val_recall: 0.6887\n",
      "Epoch 12/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc: 0.7708 - loss: 0.5669 - precision: 0.0420 - recall: 0.6360 - val_auc: 0.8023 - val_loss: 0.5814 - val_precision: 0.0376 - val_recall: 0.6887\n",
      "Epoch 13/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc: 0.7707 - loss: 0.5568 - precision: 0.0471 - recall: 0.6440 - val_auc: 0.8050 - val_loss: 0.5707 - val_precision: 0.0393 - val_recall: 0.6887\n",
      "Epoch 14/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc: 0.7833 - loss: 0.5517 - precision: 0.0461 - recall: 0.6480 - val_auc: 0.8106 - val_loss: 0.5523 - val_precision: 0.0432 - val_recall: 0.6887\n",
      "Epoch 15/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - auc: 0.7912 - loss: 0.5480 - precision: 0.0518 - recall: 0.6340 - val_auc: 0.8110 - val_loss: 0.6126 - val_precision: 0.0359 - val_recall: 0.7358\n",
      "Epoch 16/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc: 0.7983 - loss: 0.5378 - precision: 0.0481 - recall: 0.6720 - val_auc: 0.8122 - val_loss: 0.5646 - val_precision: 0.0417 - val_recall: 0.7075\n",
      "Epoch 17/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc: 0.8056 - loss: 0.5276 - precision: 0.0529 - recall: 0.6620 - val_auc: 0.8119 - val_loss: 0.5317 - val_precision: 0.0466 - val_recall: 0.7075\n",
      "Epoch 18/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc: 0.7902 - loss: 0.5407 - precision: 0.0508 - recall: 0.6440 - val_auc: 0.8187 - val_loss: 0.5422 - val_precision: 0.0460 - val_recall: 0.6981\n",
      "Epoch 19/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - auc: 0.8041 - loss: 0.5298 - precision: 0.0510 - recall: 0.6420 - val_auc: 0.8203 - val_loss: 0.5379 - val_precision: 0.0451 - val_recall: 0.6792\n",
      "Epoch 20/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - auc: 0.7997 - loss: 0.5330 - precision: 0.0528 - recall: 0.6460 - val_auc: 0.8172 - val_loss: 0.5517 - val_precision: 0.0448 - val_recall: 0.6981\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "\n",
      "--- Evaluation on Test Set ---\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7815 2034]\n",
      " [  54   97]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Legit       0.99      0.79      0.88      9849\n",
      "       Fraud       0.05      0.64      0.09       151\n",
      "\n",
      "    accuracy                           0.79     10000\n",
      "   macro avg       0.52      0.72      0.48     10000\n",
      "weighted avg       0.98      0.79      0.87     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ==========================================\n",
    "# 1. GENERATE SYNTHETIC DATASET\n",
    "# ==========================================\n",
    "print(\"Generating synthetic data...\")\n",
    "\n",
    "# Create a dataset with 50,000 samples, 30 features, and 1% fraud (imbalanced)\n",
    "X, y = make_classification(\n",
    "    n_samples=50000, \n",
    "    n_features=30, \n",
    "    n_informative=20, \n",
    "    n_redundant=2, \n",
    "    weights=[0.99, 0.01], # 99% Legit, 1% Fraud\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Convert to DataFrame to mimic real-world data structure\n",
    "feature_names = [f'V{i}' for i in range(1, 29)] + ['Time', 'Amount']\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df['Class'] = y\n",
    "\n",
    "print(f\"Data generated. Shape: {df.shape}\")\n",
    "print(f\"Fraud cases: {sum(y)}\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. PREPROCESSING\n",
    "# ==========================================\n",
    "print(\"Preprocessing data...\")\n",
    "\n",
    "# In a real scenario, we scale 'Time' and 'Amount'. \n",
    "# Since this is synthetic, all features are already roughly on the same scale, \n",
    "# but we will apply StandardScaler anyway as a best practice for Neural Networks.\n",
    "\n",
    "X_values = df.drop('Class', axis=1).values\n",
    "y_values = df['Class'].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_values)\n",
    "\n",
    "# Split into Train and Test sets\n",
    "# stratify=y ensures we have the same ratio of fraud in train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_values, test_size=0.2, random_state=42, stratify=y_values\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# 3. HANDLE IMBALANCE (Class Weights)\n",
    "# ==========================================\n",
    "# Calculate weights so the model treats the minority class (Fraud) as important\n",
    "counts = np.bincount(y_train)\n",
    "weight_for_0 = (1.0 / counts[0]) * (len(y_train) / 2.0)\n",
    "weight_for_1 = (1.0 / counts[1]) * (len(y_train) / 2.0)\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print(f\"Weight for Legit (0): {weight_for_0:.2f}\")\n",
    "print(f\"Weight for Fraud (1): {weight_for_1:.2f}\")\n",
    "\n",
    "# ==========================================\n",
    "# 4. BUILD MODEL (Deep Learning / MLP)\n",
    "# ==========================================\n",
    "model = tf.keras.models.Sequential([\n",
    "    # Input Layer & Hidden Layer 1\n",
    "    tf.keras.layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    \n",
    "    # Dropout to prevent overfitting\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    \n",
    "    # Hidden Layer 2\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    \n",
    "    # Output Layer (Sigmoid for probability 0-1)\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# ==========================================\n",
    "# 5. COMPILE MODEL\n",
    "# ==========================================\n",
    "metrics = [\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall'),\n",
    "    tf.keras.metrics.AUC(name='auc')\n",
    "]\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=metrics)\n",
    "\n",
    "# ==========================================\n",
    "# 6. TRAIN MODEL\n",
    "# ==========================================\n",
    "print(\"\\nStarting training...\")\n",
    "\n",
    "# Stop training if validation loss doesn't improve for 3 epochs\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=3, \n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    batch_size=256,       \n",
    "    epochs=20,            \n",
    "    callbacks=[early_stopping],\n",
    "    class_weight=class_weight, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# 7. EVALUATE\n",
    "# ==========================================\n",
    "print(\"\\n--- Evaluation on Test Set ---\")\n",
    "predictions = model.predict(X_test)\n",
    "y_pred = (predictions > 0.5).astype(int)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Legit', 'Fraud']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236743b4-4128-440f-a098-2514ff9559a3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e456b7-d09e-4959-b194-010c1cbbb506",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TensorFlow)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
